{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc501188",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    " - There are several benefits of feature selection\n",
    " - Some are given below:\n",
    "     - Reduces overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "     - Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "     - Reduces Training Time: Less data means that algorithms train faster.\n",
    " - In this notebook, we discuss several feature selection algorithms\n",
    "     - Algorithm 1: Dropping Constant Features using Variance Threshold Technique\n",
    "     - Algorithm 2: Feature Selection using Pearson's correlation\n",
    "     - Algorithm 3: Feature Selection using Information Gain\n",
    "     - Algorithm 4: Feature Selection using RFECV (Recursive Feature Elimination with Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc3f8b",
   "metadata": {},
   "source": [
    "# Algorithm 1 - Dropping Constant Features using Variance Threshold Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37991ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  1  4  0  1\n",
       "1  2  5  0  1\n",
       "2  4  6  0  1\n",
       "3  1  7  0  1\n",
       "4  2  8  0  1\n",
       "5  4  9  0  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Make a dataframe for the following data\n",
    "\n",
    "data = pd.DataFrame({\"A\":[1,2,4,1,2,4],\n",
    "                     \"B\":[4,5,6,7,8,9],\n",
    "                     \"C\":[0,0,0,0,0,0],\n",
    "                     \"D\":[1,1,1,1,1,1]}\n",
    "                    )\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ff53d",
   "metadata": {},
   "source": [
    "# Variance Threshold:\n",
    "\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\n",
    " - class sklearn.feature_selection.VarianceThreshold(threshold=0.0)\n",
    " - Feature selector that removes all low-variance features.\n",
    " - This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e86049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# By default, the threshold = 0 i.e. it will remove the zero-variance threshold\n",
    "var_thresh = VarianceThreshold() # by default the threshold = 0\n",
    "var_thresh.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfba0cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_thresh.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0cb7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:  Index(['A', 'B', 'C', 'D'], dtype='object')\n",
      "Features Selected:  Index(['A', 'B'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"All features: \", data.columns)\n",
    "print(\"Features Selected: \", data.columns[var_thresh.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c8185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code drops the columns based on the variance threshold algorithm\n",
    "selected_columns = data.columns[var_thresh.get_support()]\n",
    "for cols in data.columns:\n",
    "    if cols not in selected_columns:\n",
    "        data.drop(columns = cols, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c32a284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  4  6\n",
       "3  1  7\n",
       "4  2  8\n",
       "5  4  9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7ebaaf",
   "metadata": {},
   "source": [
    "# Algorithm 2 - Feature Selection with Pearson's correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f397",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    " - Highly correlated features with the target variable are important features \n",
    " - High correlation between features, (say over 90% or over 80%) indicate the existence of duplicate features.\n",
    " - In case of duplicate features, we do not need to take all the features but one one of them would suffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's load the Absenteeism dataset\n",
    "\n",
    "df = pd.read_excel('absenteeism.xls')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c099b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb88e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the independent (X) and dependent (y) features\n",
    "y = df['Absenteeism time in hours']\n",
    "X = df.drop(columns = 'Absenteeism time in hours')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca18126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dde212",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first drop the feature id as it is a personal identifier\n",
    "# Let's split the data into train and test set\n",
    "# Note that correlation will be done only on the training dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X.drop(columns = \"ID\", inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea522d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de481aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the feature correlations\n",
    "\n",
    "corr = X_train.corr()\n",
    "corr\n",
    "\n",
    "# Note that the correlation values lie between -1 and +1\n",
    "# A correlation value close to -1 indicates a strong negative linear correlation\n",
    "# A correlation value close to +1 indicates a strong positive linear correlation\n",
    "# A correlation value close to 0 indicates no linear correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A good way to visualize correlation is using a heatmap\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.heatmap(corr, annot = True, cmap = \"seismic\");\n",
    "# A link to choose different cmaps: https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc8c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of the mask \n",
    "import numpy as np\n",
    "mask1 = np.triu(np.ones_like(corr, dtype=bool))\n",
    "mask2 = np.tril(np.ones_like(corr, dtype=bool))\n",
    "plt.figure(figsize = (12,10))\n",
    "sns.heatmap(corr, annot = True, cmap = \"seismic\", mask = mask2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cafbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is highly correlated with another feature\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of the redundant columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if(abs(corr_matrix.iloc[i, j])) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlation(X_train, 0.9) # 85% is a good value of the threshold\n",
    "print(len(corr_features))\n",
    "print(corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597f03d",
   "metadata": {},
   "source": [
    "# Algorithm 3 - Feature Selection using Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf003d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read a dataset [PIMA Indians Diabetes Dataset]\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(\"Shape: \", df.shape)\n",
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate the independent (X) and dependent (y) variables\n",
    "y = df['Outcome']\n",
    "X = df.drop(columns = 'Outcome')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5097f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66499d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html\n",
    "# Estimate mutual information for a discrete target variable.\n",
    "# Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. \n",
    "# It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mutual_info = mutual_info_classif(X_train, y_train, random_state = 20)\n",
    "mutual_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mutual_info))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X_train.columns\n",
    "mutual_info.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "mutual_info.sort_values(ascending = False).plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958ca3b",
   "metadata": {},
   "source": [
    "# Algorithm 4 - Feature Selection using RFECV (Recursive Feature Elimination with Cross Validation)\n",
    "\n",
    " - URL: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    " - URL: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html\n",
    " - Feature ranking with recursive feature elimination.\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2a3ede8",
   "metadata": {},
   "source": [
    "RFE: Given an external estimator that assigns weights to features, the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute or callable. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "RFECV: Feature ranking with recursive feature elimination and cross-validated selection of the best number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfdda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=101)\n",
    "rfecv = RFECV(estimator=rfc, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c061d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07985b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Number of features selected', fontsize=14, labelpad=20)\n",
    "plt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(rfecv.support_ == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51602f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X_train.drop(X_train.columns[np.where(rfecv.support_ == False)[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e86027",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea09419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = selected_features.columns\n",
    "dset['importance'] = rfecv.estimator_.feature_importances_\n",
    "dset = dset.sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\n",
    "plt.title('RFECV - Feature importances', fontsize=20, fontweight='bold', pad=20)\n",
    "plt.xlabel('Importance', fontsize=14, labelpad=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e39ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29271da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
